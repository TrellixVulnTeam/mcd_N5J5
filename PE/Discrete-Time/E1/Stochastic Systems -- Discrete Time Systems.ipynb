{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485bc4d2",
   "metadata": {},
   "source": [
    "*Francisco Javier Sáez Maldonado*\n",
    "\n",
    "Consideramos la cadena de Markov:\n",
    "\n",
    "![Markov Chain](mc.png)\n",
    "\n",
    "En la que asumimos que cada estado hay una flecha hasta sí mismo que hace que las probabilidades en la salida sean $1$ y $p=0.3$.\n",
    "\n",
    "Únicamente con esto, podemos definir la matriz de transición:\n",
    "\n",
    "$$\n",
    "P=\\begin{pmatrix}\n",
    "1-p & p & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1-p &  p/2 & 0 & p/2 & 0 \\\\\n",
    "1/4 & 0 & 1/4 & 1/4 & 1/4 & 0\\\\\n",
    "q & 0 & 0 & 0.9-q & 0.1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1/2 & 1/2 \\\\\n",
    "0 & 0 & 0 & 1/4 & 1/2 & 1/4 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Con esto, queda resuelto el primer apartado de la entrega. Continuamos con el resto. Importamos primero las librerías necesarias para realizar los ejercicios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e80115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import nnls\n",
    "from tqdm import tqdm\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6326ce20",
   "metadata": {},
   "source": [
    "Definimos ahora dos matrices, que contendrán las dos cadenas de Markov que vamos a considerar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d54a1530",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.3\n",
    "q = 0.0\n",
    "P1 = np.array([\n",
    "    [ 1.0-p, p, 0.0, 0.0, 0.0, 0.0],                  \n",
    "    [ 0.0,1.0-p, p/2.0, 0.0 , p/2.0, 0.0],\n",
    "    [ 0.25, 0.0, 0.25, 0.25, 0.25, 0.0],\n",
    "    [ q, 0.0, 0.0, 0.9-q, 0.1, 0.0],\n",
    "    [ 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "    [ 0.0, 0.0, 0.0, 0.25, 0.5, 0.25]])\n",
    "q = 0.1\n",
    "P2 = np.array([\n",
    "    [ 1.0-p, p, 0.0, 0.0, 0.0, 0.0],                  \n",
    "    [ 0.0,1.0-p, p/2.0, 0.0 , p/2.0, 0.0],\n",
    "    [ 0.25, 0.0, 0.25, 0.25, 0.25, 0.0],\n",
    "    [ q, 0.0, 0.0, 0.9-q, 0.1, 0.0],\n",
    "    [ 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "    [ 0.0, 0.0, 0.0, 0.25, 0.5, 0.25]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c05f9f",
   "metadata": {},
   "source": [
    "Podemos definir ahora una clase `MarkovChain`. Esta clase estará inicializada únicamente con la matriz de transición que determina a nuestra cadena de Markov. Realizamos una serie de métodos para la clase, que nos realizarán esencialmente los ejercicios que tenemos que hacer. Entre ellos están:\n",
    "\n",
    "- `_next`, que nos devuelve un paso empírico en una simulación de un experimento usando una cadena de Markov.\n",
    "- `_simulation`, que nos realiza la simulación completa (utilizando la función anterior)\n",
    "- `_simulation_position`, que hace una simulación hasta encontrar un estado y devuelve la posición en la que se encuentra, o $-1$.\n",
    "- `empirical_h`, que nos calcula la probabilidad probabilidad de pasar por un estado, usando $n$ experimentos diferentes\n",
    "- `empirical_k`, que nos calcula la media de tiempo en alcanzar un estado usando $n$ experimentos\n",
    "- `theoretical_h`, `theoretical_k`, que calculan las cantidades anteriores pero de forma teórica usando la matriz $P$ y resolviendo el sistema de ecuaciones teórico (necesario para la cuarta pregunta).\n",
    "- `probability_H`, que nos calcula la probabilidad teórica de $P[H_m^A = t]$.\n",
    "- `probability_empirical_H`, que nos calcula la probabilidad empírica $P[H_m^A = t]$ realizando simulaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8714730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovChain:\n",
    "\n",
    "    \"\"\"\n",
    "    Class that encapsulates the behaviour of a Markov chain, determined by its transition matrix.\n",
    "    This class makes simulations using different methods (with and without stops) and computes both \n",
    "    first hitting time and average hitting time between any two given states, using the class methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, P):\n",
    "        \"\"\"\n",
    "        Inicialization of the Markov chain\n",
    "        - P: transition matrix\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        self.n = len(P[0])\n",
    "        \n",
    "        \n",
    "    def _next(self,curr_m):\n",
    "        \"\"\"\n",
    "        Simulate an empirical step using an uniform distribution.\n",
    "        Idea: divide [0,1] in n_states parts, where the measure of each\n",
    "        part is its probability and use cumulative_sum(probabilities) >= generated_number\n",
    "        - curr_m: current state\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate from the Uniform(0,1)\n",
    "        gen = random.rand()\n",
    "   \n",
    "        # Return index of the first state that matches the condition\n",
    "        return int(np.where(np.cumsum(self.P[curr_m]) >= gen)[0][0])\n",
    "    \n",
    "    def _simulation(self, m_ini, t):\n",
    "        \"\"\"\n",
    "        Generate complete simulation of t time steps, beginning in the state m_ini\n",
    "        - m_ini: initial state\n",
    "        - t: time steps that will be done\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize states\n",
    "        states = [0]*t\n",
    "        # Compute first jump\n",
    "        states[0] = self._next(m_ini)\n",
    "        # Loop to compute jumps\n",
    "        for i in range(1,t):\n",
    "            states[i] = self._next(states[i-1])\n",
    "    \n",
    "        return states\n",
    "    \n",
    "    def _simulation_position(self,m_ini,m_end,t):\n",
    "        \"\"\"\n",
    "        Generate a simulation that will stop in t time steps or right after finding the state m_end\n",
    "        - m_ini: initial state\n",
    "        - m_end: final state\n",
    "        - t: maximum time steps\n",
    "        \"\"\"\n",
    "        # Change the variable name\n",
    "        curr = m_ini\n",
    "        # Return if it is in the first step\n",
    "        if curr == m_end:\n",
    "            return 0\n",
    "        # Loop over the possible time steps\n",
    "        for i in range(1,t):\n",
    "            following = self._next(curr)\n",
    "            # Stop condition\n",
    "            if following == m_end:\n",
    "                return i\n",
    "            curr = following\n",
    "        \n",
    "        return -1\n",
    "        \n",
    "    \n",
    "    def empirical_h(self,m_ini, m_end, t, n):\n",
    "        \"\"\"\n",
    "        Compute the empirical hitting h_{m_ini}^{m_end} time, using n experiments of t time steps\n",
    "        - m_ini: initial state\n",
    "        - m_end: final state\n",
    "        - t: time steps\n",
    "        - n: number of experiments\n",
    "        \"\"\"\n",
    "        # Trivial case\n",
    "        if m_ini == m_end:\n",
    "            return 1.0\n",
    "        # Find if the searched state is in the simulation\n",
    "        hit = [1 if m_end in self._simulation(m_ini, t) else 0 for _ in range(n)]\n",
    "        # Obtain all hits\n",
    "        hits = np.sum(hit)\n",
    "        # Return probability\n",
    "        return hits/n\n",
    "    \n",
    "    def empirical_k(self, m_ini, m_end, t, n):\n",
    "        \"\"\"\n",
    "        Compute the average time k_{m_ini}^{m_end} of hitting m_end from m_ini, using n experiments of t time steps\n",
    "        - m_ini: initial state\n",
    "        - m_end: final state\n",
    "        - t: time steps\n",
    "        - n: number of experiments\n",
    "        \"\"\"\n",
    "        \n",
    "        if m_ini == m_end:\n",
    "            return 0.0\n",
    "        \n",
    "        # Get the simulations stopping if we find our position\n",
    "        simulations = [ self._simulation_position(m_ini,m_end,t) for _ in range(n)]\n",
    "        \n",
    "        # Return average or infinity\n",
    "        return np.Infinity if -1 in simulations else np.mean(simulations)\n",
    "        \n",
    "    def theoretical_h(self, m_end):\n",
    "        \"\"\"\n",
    "        Compute the theoretical hitting probability of the state m_end from any of the states\n",
    "        It uses the Matrix form of the Linear Equations system Ax = b\n",
    "        - m_end: final state\n",
    "        \"\"\"\n",
    "        # Compute the matrix A \n",
    "        A = self.P - np.diag(np.ones(self.n))\n",
    "        # Compute b\n",
    "        b = np.zeros(self.n)\n",
    "        # Force conditions to match the theorem conditions\n",
    "        b[m_end] = 1\n",
    "        A[m_end] = b\n",
    "        \n",
    "        # Solve using nnls\n",
    "        return nnls(A, b)[0]\n",
    "        \n",
    "        \n",
    "    def theoretical_k(self, m_end, m_ini = None):\n",
    "        \"\"\"\n",
    "        Compute the theoretical average hitting time of the state m_end from any of the states\n",
    "        It uses the Matrix form of the Linear Equations system Ax = b\n",
    "        - m_end: final state\n",
    "        - m_ini (optional). Used for infinite time corrections\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check infinite time problem\n",
    "        if m_ini != None:\n",
    "            theo_h = self.theoretical_h(m_end)[m_ini]\n",
    "            if theo_h < 1:\n",
    "                return [np.Infinity]*self.n\n",
    "                \n",
    "        # Compute A and b\n",
    "        A = np.diag(np.ones(self.n)) - self.P\n",
    "        b = np.ones(self.n)\n",
    "        # Match the conditions of the theorem\n",
    "        b[m_end] = 0\n",
    "        A[m_end] = np.logical_not(b)\n",
    "        \n",
    "        # Solve using nnls\n",
    "        return nnls(A, b)[0]\n",
    "        \n",
    "    def probability_H(self, m_ini, m_end, max_t ):\n",
    "        \"\"\"\n",
    "        Computes theoretical probability of being in the state m_end from m_ini in exactly t movements, for\n",
    "        a range of ts: (0,max_t). It is computed using a recurrence explained in this notebook.\n",
    "        - m_ini: initial state\n",
    "        - m_end: final state\n",
    "        - max_t: maximum of the different time steps taken.\n",
    "        \"\"\"\n",
    "    \n",
    "        # Recurrence indexes, all but m_end\n",
    "        idx = list(np.arange(self.n))\n",
    "        idx.remove(m_end)\n",
    "        \n",
    "        # Result\n",
    "        g = np.zeros(max_t + 1)\n",
    "        \n",
    "        # Initial iteration, P[i,j]\n",
    "        f = self.P[idx,m_end]\n",
    "        \n",
    "        # Compute first 2 iterations separatedly since they are not computed the same way\n",
    "        g[0] = 0\n",
    "        g[1] = f[m_ini]\n",
    "        # Rest of iterations\n",
    "        for t in range(2,max_t + 1):\n",
    "            f = [f @ self.P[i,idx] for i in idx]\n",
    "            g[t] = f[m_ini]\n",
    "            \n",
    "        return g\n",
    "    \n",
    "    def probability_empirical_H(self,m_ini,m_end,max_t,n):\n",
    "        \"\"\"\n",
    "        Computes empirical probability of being in the state m_end from m_ini in exactly t movements, for\n",
    "        a range of ts: (0,max_t). n experiments are performed to achieve this.\n",
    "        - m_ini: initial state\n",
    "        - m_end: final state\n",
    "        - max_t: maximum of the different time steps taken.\n",
    "        - n: number of experiments.\n",
    "        \"\"\"\n",
    "        \n",
    "        g = np.zeros(max_t+1)\n",
    "        \n",
    "        g[0] = 0\n",
    "        for t in tqdm(range(1,max_t)):\n",
    "            # Get the simulations\n",
    "            simulation_positions = np.array([ self._simulation_position(m_ini,m_end, t) for _ in range(n)])\n",
    "            \n",
    "            # Get where we find it in the right position.\n",
    "            # t-1 is dued to how _simulation_position works\n",
    "            times = np.where(simulation_positions == t-1)[0]\n",
    "            \n",
    "            # Return probability\n",
    "            g[t-1] = len(times)/n\n",
    "            \n",
    "        return g\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe2c93",
   "metadata": {},
   "source": [
    "Con esta clase, podemos declarar nuestros objetos Cadena de Markov del siguiente modo (declaramos uno para cada una de las matrices de transición). Vamos a usar $t = 1000$ instantes de tiempo para evaluar todos los experimentos y, en el caso de tener que promediar la salida de varios experimentos, usaremos $n = 1000$ experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15a96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "t = 1000\n",
    "mc = MarkovChain(P1)\n",
    "mc1 = MarkovChain(P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343b9e6a",
   "metadata": {},
   "source": [
    "\n",
    "**Ejercicio 2.-** Simular el funcionamiento de la cadena y hacer una estimación de conjunto de $h_0^2$ y $h_0^5$ para $q = 0.1$ y $q = 0$.\n",
    "\n",
    "Ahora, podemos simular el funcionamiento de la cadena usando `empirical_h` sobre cada una de las cadenas para estimar $h_0^2$ y $h_0^5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d517f944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical probabilities h\n",
      "Con q = 0\n",
      "\t h02 = 0.53\n",
      "\t h05 = 1.0\n",
      "Con q = 0.1\n",
      "\t h02 = 1.0\n",
      "\t h05 = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Empirical probabilities h\")\n",
    "print(\"Con q = 0\")\n",
    "print(\"\\t h02 = {}\".format(mc.empirical_h(0 , 2 , n, t)))\n",
    "print(\"\\t h05 = {}\".format(mc.empirical_h(0 , 5 , n, t)))\n",
    "print(\"Con q = 0.1\")\n",
    "print(\"\\t h02 = {}\".format(mc1.empirical_h(0 , 2 , n, t)))\n",
    "print(\"\\t h05 = {}\".format(mc1.empirical_h(0 , 5 , n, t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ef3d9",
   "metadata": {},
   "source": [
    "Podemos ver que :\n",
    "\n",
    "- Cuando usamos $q = 0$, la probabilidad llegar de $0$ a $5$ ($h_0^5$), es $1$ , mientras que la de llegar del estado $0$ al $2$ ($h_0^2$) es de aproximadamente $\\frac{1}{2}$. Esto ocurre porque en el primer caso, tenemos una clase cerrada $\\{3,4,5\\}$ y por tanto, si ocurre la secuencia: $0\\to 1 \\to 4$, ya no hay forma de volver al segundo estado.\n",
    "\n",
    "- Al aumentar $q = 0.1$, la probabilidad de llegar del estado $0$ al $2$ pasa automáticamente a ser 1. Esto tiene sentido, Al *activar* la vuelta desde el nodo $3$ al nodo $0$, ya no tenemos esta clase cerrada y podemos volver al estado inicial.\n",
    "\n",
    "**Ejercicio 3.-** Simular el funcionamiento de la cadena y hacer una estimación de conjunto de $k_0^2$ y $k_4^2$ para $q = 0.1$ y $q = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8fabb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical means k\n",
      "Con q = 0\n",
      "\t k02 = inf\n",
      "\t k42 = inf\n",
      "Con q = 0.1\n",
      "\t k02 = 41.457\n",
      "\t k42 = 77.131\n"
     ]
    }
   ],
   "source": [
    "print(\"Empirical means k\")\n",
    "print(\"Con q = 0\")\n",
    "print(\"\\t k02 = {}\".format(mc.empirical_k(0 , 2 , n, t)))\n",
    "print(\"\\t k42 = {}\".format(mc.empirical_k(4 , 2 , n, t)))\n",
    "print(\"Con q = 0.1\")\n",
    "print(\"\\t k02 = {}\".format(mc1.empirical_k(0 , 2 , n, t)))\n",
    "print(\"\\t k42 = {}\".format(mc1.empirical_k(4 , 2 , n, t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94021ae5",
   "metadata": {},
   "source": [
    "Obtenemos las siguientes conclusiones:\n",
    "\n",
    "- Con $q = 0$, tenemos un comportamiento parecido al que ocurre en el caso del *first hitting time*. Empezando desde el estado $4$, que está en una clase cerrada, nunca se puede salir de esa clase. Empezando desde el $0$, al tener una clase cerrada, en algunos casos nunca se llegará al estado $2$, por lo que tendremos tiempos infinitos y la media será de nuevo infinito. \n",
    "\n",
    "- Repitiendo de nuevo el razonamiento, al eliminar la clase cerrada, siempre podremos llegar a todos los estados en cualquier momento, por lo que la media deja de ser infinito.\n",
    "\n",
    "**Ejercicio 4.-** Usar el sistema de ecuaciones lineares oportuno para determinar los valores teóricos correspondientes\n",
    "a las cantidades estimadas y comparar con los valores determinados por medio de la simulación\n",
    "\n",
    "Planteamos primero la base teórica. Sabemos que, el vector de las *hitting probabilities* $h_m^n$ de un conjunto $A\\subseteq M$, es decir $h^A = [h^A_m| m \\in M]'$ es la solución minimal no negativa del sistema:\n",
    "$$\n",
    "\\begin{cases}\n",
    "h_m^A = 1 & m \\in A\\\\\n",
    "h_m^A= \\sum_{n\\in M} P_{m,n} h_n^A & m \\notin A\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Es por ello que, lo que debemos expresar nuestro sistema como un sistema lineal de la forma $Ax = b$. Dada la matriz de transición $P$ y el vector $h = [h_0^m,\\dots,h_n^m]'$. Podemos tomar como punto de partida el sistema $Ph = h$. Podemos despejarlo matricialmente para obtener el sistema $(P - I_n)h = 0$. Este sistema no está cumpliendo la primera restricción del teorema. Para conseguirlo, debemos\n",
    "\n",
    "- Sustituir la fila $m-$ésima por un vector $v = [0,\\dots,1,\\dots,0]$, donde el $1$ está en la posición $m$.\n",
    "- Sustituir el $0$ matricial por el vector $v^T$.\n",
    "\n",
    "Con estas condiciones, podemos tratar de buscar la solución minimal no negativa del sistema. Para ello, tenemos la función `nnls` de `scipy`, que nos resuelve el problema\n",
    "$$\n",
    "\\operatorname{arg}\\min_x || Ax-b||_2\\quad \\quad x \\geq 0,\n",
    "$$\n",
    "que es justo la solución que nos interesa.\n",
    "\n",
    "En nuestro caso, la función `mc.theoretical_h` nos da la probabilidad teórica de llegar al estado `m_end` empezando desde cada uno de los estados iniciales y  en un número de pasos de tiempo $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd99490d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical probabilities h\n",
      "Con q = 0\n",
      "\t h02 = 0.5\n",
      "\t h05 = 0.9999999999999986\n",
      "Con q = 0.1\n",
      "\t h02 = 1.0000000000000007\n",
      "\t h05 = 0.9999999999999981\n"
     ]
    }
   ],
   "source": [
    "print(\"Theoretical probabilities h\")\n",
    "print(\"Con q = 0\")\n",
    "print(\"\\t h02 = {}\".format(mc.theoretical_h(2)[0]))\n",
    "print(\"\\t h05 = {}\".format(mc.theoretical_h(5)[0]))\n",
    "print(\"Con q = 0.1\")\n",
    "print(\"\\t h02 = {}\".format(mc1.theoretical_h(2)[0]))\n",
    "print(\"\\t h05 = {}\".format(mc1.theoretical_h(5)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09061891",
   "metadata": {},
   "source": [
    "Vemos como obtenemos, salvo errores de redondeo, los mismos valores que se obtenían de forma empírica, por lo que podemos decir que nuestros resultados anteriores son correctos.\n",
    "\n",
    "Del mismo modo, sabemos que el vector de los *mean hitting times* $k_m^n$ de un conjunto $A \\subseteq M$, es decir, $k^A = [k_m^A | m \\in M]'$ es la solución minimal no negativa del sistema:\n",
    "$$\n",
    "\\begin{cases}\n",
    "k_m^A = 0 & m \\in A\\\\\n",
    "k_m^A= 1 + \\sum_{n\\in M} P_{m,n} k_n^A & m \\notin A\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Cambiamos un poco el razonamiento, aunque es parecido al caso anterior. Podemos escribir la expresión de abajo como $k = 1 + Pk \\Rightarrow 1 = (I - P)$. Con esto, hacemos el mismo razonamiento que en el caso anterior, salvo que ahora nuestro vector $v$ será $v = [1,\\dots,0,\\dots,1]$, que tiene un $0$ en la posición $m$.\n",
    "\n",
    "Además, hay que tener en cuenta que si el valor medio es infinito, no podemos obtener esta solución mediante el sistema, pero sabemos que esto es equivalente a tener un $h_m^n < 1$, por lo que primero calculamos este valor y si ocurre que es menor que uno, devolveremos infinito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b8d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical means k\n",
      "Con q = 0\n",
      "\t k02 = inf\n",
      "\t k42 = inf\n",
      "Con q = 0.1\n",
      "\t k02 = 43.33333333333339\n",
      "\t k42 = 73.33333333333343\n"
     ]
    }
   ],
   "source": [
    "print(\"Theoretical means k\")\n",
    "print(\"Con q = 0\")\n",
    "print(\"\\t k02 = {}\".format(mc.theoretical_k(2,m_ini = 0)[0]))\n",
    "print(\"\\t k42 = {}\".format(mc.theoretical_k(2,m_ini = 4)[4]))\n",
    "print(\"Con q = 0.1\")\n",
    "print(\"\\t k02 = {}\".format(mc1.theoretical_k(2, m_ini = 0)[0]))\n",
    "print(\"\\t k42 = {}\".format(mc1.theoretical_k(2, m_ini = 4)[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d13016",
   "metadata": {},
   "source": [
    "De nuevo, obtenemos el resultado que habíamos obtenido empíricamente, por lo que podemos de nuevo reafirmarnos en que nuestro resultado anterior era correcto.\n",
    "\n",
    "**Ejercicio 5.-** En el caso $q =0.1$, dibujar el gráfico de \n",
    "$$\n",
    "g(t) = \\mathbb P[H_0^{\\{4\\}} = t]\n",
    "$$\n",
    "\n",
    "Se nos pide dibujar la función que nos da para cada instante de tiempo $t$, la probabilidad de que ese instante de tiempo $t$ sea el *first hitting time* del estado $4$ si hemos partido del $0$. Queremos el gráfico teórico. Podemos encontrar este valor de forma recurrente, en los siguientes pasos:\n",
    "\n",
    "1. Consideramos $k$ el estado final.\n",
    "2. Para llegar a $k$ desde otro estado $j\\neq k$, el *first hitting time* del estado $j$ debe ser $t-1$. Queremos calcular entonces $\\mathbb P[H_i^j = t-1]$. Debemos sumar en todos los posibles estados anteriores.\n",
    "3. De nuevo, para llegar hasta $j$ desde otro estado $z$, repetimos el razonamiento para obtener que tenemos que calcular $\\mathbb P[H_i^z = t-2]$. Debemos de nuevo sumar en todos los posibles estados anteriores.\n",
    "\n",
    "Si llamamos $f_{ij}^{(t)} = \\mathbb P[H_i^j = t]$ y sabiendo que $f_{ij}^{(1)} = P_{ij}$, en general, podemos hacer la recurrencia:\n",
    "$$\n",
    "f_{ij}^{(t)} = \\sum_{k \\neq j} P_{ik}f_{kj}^{(t-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fbe58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probability_H(markov_chain, m_ini, m_end, max_t,n):\n",
    "    gs = markov_chain.probability_H(m_ini,m_end,max_t)\n",
    "    gs_empirical = markov_chain.probability_empirical_H(m_ini,m_end,max_t,n)\n",
    "    \n",
    "    #fig, axs = plt.subplots(1, 3)\n",
    "    \n",
    "    #axs[0,0]\n",
    "    \n",
    "    plt.plot(np.arange(0,max_t+1),gs,\"--\",lw = 3,label = \"Theoretical\")\n",
    "    plt.plot(np.arange(0,max_t+1),gs_empirical,lw = 2,color = \"red\",alpha = 0.8,label = \"Empirical\")\n",
    "    plt.ylabel(\"g(t)\")\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.legend()\n",
    "    \n",
    "    print(\"Maximum = {}\".format(max(gs)))\n",
    "    print(\"The maximum is in t = {}\".format(np.argmax(gs)))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfea8ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [00:45<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum = 0.08629312499999998\n",
      "The maximum is in t = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_probability_H(mc,0,4,100,10**4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2cbf65",
   "metadata": {},
   "source": [
    "Podemos comprobar como la función $g(t)$ empírica, cuando aumentamos el número de veces que repetimos el experimento a un número suficientemente grande (en este caso, hemos usado $10^4$), aproxima de forma suficientemente buena a la función $g$ teórica que hemos hallado usando la recurrencia.\n",
    "\n",
    "Obtenemos que el número de instantes de tiempo en el que es más probable que tras ese número de instantes hayamos llegado desde el estado $0$ al estado $4$ es $5$, aunque con una probabilidad relativamente baja.\n",
    "\n",
    "**Ejercicio 5.-** Afirmo que $H_0^4 < H_0^5$ siempre. ¿ Es cierto ? ¿ Por qué sí ?\n",
    "\n",
    "Podemos mirar el grafo de la cadena de Markov para ver que la única forma de llegar al estado $5$ es habiendo pasado antes por el estado $4$. Además, vemos que del estado $4$ sólo puede llegarse al $5$, por lo que si $H_0^5 = t$, entonces obligatoriamente $H_0^4 \\leq t-1$ siempre, por lo que tenemos que $H_0^4 < H_0^5$ siempre."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
