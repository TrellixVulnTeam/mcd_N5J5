{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0160a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading GitHub repo tidyverse/lubridate@HEAD\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m✔\u001b[39m  \u001b[90mchecking for file ‘/tmp/RtmpjdjCB7/remotes46ac07496940a/tidyverse-lubridate-db83436/DESCRIPTION’\u001b[39m\u001b[36m\u001b[39m\n",
      "\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mpreparing ‘lubridate’:\u001b[39m\u001b[36m\u001b[39m\n",
      "\u001b[32m✔\u001b[39m  \u001b[90mchecking DESCRIPTION meta-information\u001b[39m\u001b[36m\u001b[39m\n",
      "\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mcleaning src\u001b[39m\u001b[36m\u001b[39m\n",
      "\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mrunning ‘cleanup’\u001b[39m\u001b[36m\u001b[39m\n",
      "\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mchecking for LF line-endings in source and make files and shell scripts\u001b[39m\u001b[36m\u001b[39m\n",
      "\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mchecking for empty or unneeded directories\u001b[39m\u001b[36m\u001b[39m\n",
      "   Removed empty directory ‘lubridate/revdep’\n",
      "\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mbuilding ‘lubridate_1.8.0.tar.gz’\u001b[39m\u001b[36m\u001b[39m\n",
      "   \n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/fjaviersaezm/R/x86_64-pc-linux-gnu-library/4.1’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Warning message in i.p(...):\n",
      "“installation of package ‘/tmp/RtmpjdjCB7/file46ac0d2ba299/lubridate_1.8.0.tar.gz’ had non-zero exit status”\n"
     ]
    }
   ],
   "source": [
    "devtools::install_github(\"tidyverse/lubridate\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e308a8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(tidyverse): there is no package called ‘tidyverse’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(tidyverse): there is no package called ‘tidyverse’\nTraceback:\n",
      "1. suppressMessages(library(tidyverse))",
      "2. withCallingHandlers(expr, message = function(c) if (inherits(c, \n .     classes)) tryInvokeRestart(\"muffleMessage\"))",
      "3. library(tidyverse)"
     ]
    }
   ],
   "source": [
    "suppressMessages(library(tidyverse))\n",
    "suppressMessages(library(reshape2))\n",
    "defaultW <- getOption(\"warn\")\n",
    "options(warn = -1)\n",
    "options(repr.plot.width=12, repr.plot.height=8)\n",
    "\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(KernSmooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9062c",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "Los datos del fichero *Datos-geyser.txt* corresponden al día de la observación (primera\n",
    "columna), el tiempo medido en minutos (segunda columna Y ) y el tiempo hasta la siguiente\n",
    "erupción (tercera columna X) del geyser *Old-Faithful* en el parque norteamericano de\n",
    "*Yellowstone*.\n",
    "\n",
    "a) Representa gráficamente los datos, junto con el estimador de Nadaraya-Watson de la\n",
    "función de regresión de Y sobre X.\n",
    "\n",
    "b) Representa gráficamente los datos, junto con el estimador localmente lineal de la función\n",
    "de regresión de Y sobre X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23709c87",
   "metadata": {},
   "source": [
    "Comenzamos leyendo los datos del conjunto de datos especificado, quedádonos con las columnas que nos interesan para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b3efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(read.table(\"Datos-geyser.txt\", header = TRUE))[, c(\"X\",\"Y\")]\n",
    "n <- nrow(df)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8873298e",
   "metadata": {},
   "source": [
    "Estamos preparados para dibujar el **apartado a**. Usamos la función `geom_smooth` pasándole como parámetro `method = loess` y parámetros del método `degree = 0`, que nos dará el estimador de Nadayara-Watson de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9b9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ggplot(df,aes(X,Y)) +\n",
    "    geom_point(color = \"blue\")+\n",
    "    geom_smooth( method = 'loess', se = FALSE, span = 0.25, method.args = list(degree=0), col = 'red')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d07abed",
   "metadata": {},
   "source": [
    "A continuación, queremos hacer para el **apartado b** el estimador localmente lineal. Debemos volver a usar la función `geom_smooth` con `method = loess`, pero ahora le damos como parámetro a este método `degree = 1`, para obtener el estimador localmente lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ff148",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df,aes(X,Y)) +\n",
    "    geom_point(color = \"blue\")+\n",
    "    geom_smooth( method = 'loess', se = FALSE, span = 0.25, method.args = list(degree=1), col = 'chartreuse4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea581add",
   "metadata": {},
   "source": [
    "Con objeto de comparar ambos estimadores, vamos a dibujar los dos en el mismo gráfico para observar sus diferencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df,aes(X,Y)) +\n",
    "    geom_point(color = \"blue\")+\n",
    "    geom_smooth(aes(colour=\"Locally linear\"),formula=y~x, method = 'loess', se = FALSE, span = 0.25, method.args = list(degree=1))+\n",
    "    geom_smooth(aes(colour=\"Nadayara-Watson\"),formula=y~x,  method = 'loess', se = FALSE, span = 0.25, method.args = list(degree=0))+\n",
    "    scale_color_manual(name = \"Estimators\", values = c('chartreuse4','red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231e563",
   "metadata": {},
   "source": [
    "# Ejercicio 4\n",
    "\n",
    "Se considera el siguiente modelo de regresión lineal múltiple:\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i3} + \\epsilon_i , \\quad \\epsilon_i \\sim \\mathcal N(0,\\sigma^2), \\quad i = 1,\\dots,n \\ \\ \\ (1)\n",
    "$$\n",
    "\n",
    "Se dispone de $n=20$ observaciones con las que se ajustan todos los posibles submodelos del\n",
    "modelo (1), obteniéndose para cada uno de ellos las siguientes sumas de cuadrados de los\n",
    "residuos (todos los submodelos incluyen un término independiente).\n",
    "\n",
    "| Variables incluidas en el modelo | SCR       |\n",
    "|:----------------------------------:|:-----------:|\n",
    "| Término independiente.           | $42644.00$|\n",
    "| $x_1$                            | $8352.28$ |\n",
    "| $x_2$                            | $36253.69$|\n",
    "| $x_3$                            | $36606.19$|\n",
    "| $x_1,x_2$                        | $7713.13$ |\n",
    "| $x_1,x_3$                        | $762.55$  |\n",
    "| $x_2,x_3$                        | $32700.17$|\n",
    "| $x_1,x_2,x_3$                    | $761.41$  |\n",
    "\n",
    "**a)** Calcula la tabla de análisis de la varianza para el modelo $(1)$ y contrasta a nivel $\\alpha = 0.05$ la hipótesis nula:\n",
    "$$\n",
    "H_0 : \\beta_1 = \\beta_2 = \\beta_3 = 0\n",
    "$$\n",
    "\n",
    "**Solución**\n",
    "\n",
    "Para calcular la tabla de análisis de la varianza necesitamos:\n",
    "\n",
    "- Grados de libertad (df)\n",
    "- Suma de cuadrados explicada (SumSq)\n",
    "- Media de los cuadrados (MeanSq)\n",
    "- Valor del estadístico $F$, calculado como $$F= \\frac{SCE/p}{SCR/(n-p-1)} $$\n",
    "- P-value, que sabemos que lo podemos calcular usando la región crítica $$ R = \\left\\{ \\frac{(\\mbox{SCR}_0 - \\mbox{SCR})/k}{\\mbox{SCR}/(n-p-1)} > F_{k,n-p-1;\\alpha}  \\right\\}$$.\n",
    "\n",
    "Necesitamos saber cuál es la suma de cuadrados explicada. Sin embargo, con la información que tenemos en la tabla podemos razonar del siguiente modo: Sabemos que en un modelo constante $Y_i = \\beta_0 + \\epsilon_i$, el valor de $\\beta_0$ que minimiza el error cuadrátrico medio entre los valores observados y las predicciones que nuestro modelo hace es justamente $\\hat \\beta_0 = \\bar Y$. Ahora, usando con este modelo reducido que la varianza total es igual a la suma de la varianza explicada por el modelo más la varianza no explicada por el mismo:\n",
    "\n",
    "$$\n",
    "SCE = SCT - SCT = \\sum(\\bar Y - Y_i)^2 - \\sum (\\hat Y_i - Y_i)^2 = \\sum (\\hat \\beta_0 - Y_i)^2 - \\sum(\\hat Y_i - Y_i)^2 = SCR_0 - SCR\n",
    "$$\n",
    "\n",
    "Así que podemos usar la diferencia entre la suma de los cuadrados de los residuos del modelo reducido que tiene solo el término independiente y la suma de los cuadrados de los residuos del modelo completo $(1)$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- 20\n",
    "p <- 3\n",
    "\n",
    "srsums <- c(42644.00,8352.28,36253.69,36606.19,7713.13,762.55,32700.17,761.41)\n",
    "scr <- srsums[8]\n",
    "sce <- srsums[1] - scr\n",
    "\n",
    "models <- c(\"Model\",\"Residuals\")\n",
    "df <- c(p,n-p-1)\n",
    "sumsq <- c(sce,scr)\n",
    "meansq <- (sumsq/df)\n",
    "f_val <- c(meansq[1]/meansq[2],NA)\n",
    "pval <- c(pf(f_val[1], df1 = p , df2 = n-p-1, lower.tail = FALSE), NA)\n",
    "\n",
    "table <- data.frame(Model=models,Df = df, Sumsq = sumsq, Meansq = meansq, F = f_val, P_val = pval)\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef092c0",
   "metadata": {},
   "source": [
    " \n",
    " Ahora, se nos pide contrastar la hipótesis nula $H_0$. Para ello, usamos el estadístico $F$ comentado anteriormente. Además, sabemos que bajo $H_0$ se sigue una distribución $F_{3;16}$, por lo que nuestro p-valor es $$ p = \\mathbb P[F_{3;16} > F] = 3.42 \\cdot 10^{-14} << 0.05 = \\alpha,$$\n",
    " por lo podemos rechazar la hipótesis nula de que $\\beta_1 = \\beta_2 = \\beta = 3 = 0$.\n",
    " \n",
    " **b)** En el modelo $(1)$, contrasta a nivel $\\alpha = 0.05$ las dos hipótesis nulas siguientes:\n",
    " - $H_0: \\beta_2 = 0$\n",
    " - $H_0 = \\beta_1 = \\beta_3 = 0$.\n",
    " \n",
    " \n",
    "**Solución**\n",
    " \n",
    " En ambos casos, necesitamos ahora un nuevo estimador, que sabemos que es \n",
    "$$F =  \\frac{(\\mbox{SCR}_0 - \\mbox{SCR})/k}{\\mbox{SCR}/(n-p-1)} \\equiv F_{k,n-p-1}$$\n",
    "donde $n$ es el número de muestras, $p$ el número de variables del modelo completo y $k$ el rango de la matriz $A$, matriz que verifica que $H_0 = A\\mathbf{\\beta} = 0$. En este caso, $SCR_0$ es el valor de la suma de los cuadrados de los residuos del modelo ajustado bajo la hipótesis nula, valor que obtendremos de la tabla del enunciado.\n",
    "\n",
    "- Si $H_0 = \\beta_2$ = 0, tenemos que la matriz $A$ tiene que ser $$ A = (0 \\ 0 \\ 1 \\ 0),$$ por lo que $k = rango(A) =  1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k <- 1\n",
    "F <- ((srsums[6] - scr)/k)/(scr/(n-p-1))\n",
    "pval1 <- pf(F, df1 = k, df2 = n-p-1, lower.tail = FALSE)\n",
    "print(\"p-value:\")\n",
    "pval1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800d3314",
   "metadata": {},
   "source": [
    "En este caso, hemos obtenido un $p-$value de $0.8789$, que es considerablemente mayor que $0.05$, por lo que no tenemos evidencia para rechazar la hipótesis nula de que la segunda variable no es significativa para la predicción de nuestro modelo.\n",
    "\n",
    "- Si $H_0 : \\beta_1 = \\beta_3 = 0$, en este caso podemos considerar la siguiente matriz A:\n",
    "$$\n",
    "A = \\begin{pmatrix} 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1\\end{pmatrix},\n",
    "$$\n",
    "que cumple que $H_0 = A \\mathbf{\\beta}$ y que, como tiene dos columnas independientes, tiene como $k = rango(A) = 2$. Repetimos los cálculos anteriores pero ahora usando los valores necesarios de la tabla inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k <- 2\n",
    "F <- ((srsums[3] - scr)/k) / (scr/(n-p-1))\n",
    "pval2 <- pf(F, df1=k, df2=n-p-1,lower.tail=FALSE)\n",
    "print(\"p-value\")\n",
    "pval2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f915db1",
   "metadata": {},
   "source": [
    "En este último caso, hemos obtenido que el $p-$value es de $3.79\\cdot 10^{-14}$, que es considerablemente menor que $\\alpha = 0.05$, por lo que rechazamos la hipótesis nula de que tanto $\\beta_1$ como $\\beta_3$ no son importantes para las predicciones de nuestro modelo.\n",
    "\n",
    "# Ejercicio 6\n",
    "\n",
    "Sean $Y_1,Y_2,Y_3$ tres variables aleatorias independientes con distribución normal. Supongamos que $\\mu,\\lambda \\in \\mathbb R$ y que\n",
    "- $Y_1 \\sim \\mathcal N(\\mu,\\sigma^2)$\n",
    "- $Y_2 \\sim \\mathcal N(\\lambda,\\sigma^2)$\n",
    "- $Y_3 \\sim \\mathcal N(\\mu + \\lambda,\\sigma^2)$\n",
    "\n",
    "**a)** Demuestra que el vector $\\mathbf Y = (Y_1,Y_2,Y_3)'$ verifica el modelo de regresión múltiple $\\mathbf Y = \\mathbf{X\\beta} + \\mathbf \\epsilon$. Para ello, determina la matriz de diseño $\\mathbf X$, el vector de parámetros $\\mathbf \\beta$, y la distribución de las variables de error $\\mathbf \\epsilon$.\n",
    "\n",
    "**b)** Calcula los estimadores de máxima verosimilitud (equivalentemente, el de mínimos cuadrados) de $\\lambda$ y $\\mu$.\n",
    "\n",
    "**c)** Calcula la distribución del vector $(\\hat \\lambda, \\hat \\mu)'$ formado por los estimadores calculados en el apartado anterior.\n",
    "\n",
    "**Solución**\n",
    "\n",
    "**Apartado a)**. Sabemos que El vector $\\mathbf Y = (Y_1,Y_2,Y_3)'$ Sigue una distribución normal multivariante $\\mathbf Y \\sim \\mathcal N_3 (\\mathbf \\mu, \\mathbf \\Sigma)$, donde $\\mathbf {\\mu} = (\\mu, \\lambda, \\lambda + \\mu)$ es el vector de medias y $\\mathbf \\Sigma$ es la matriz de covarianzas. Ahora basta ver que, considerando \n",
    "$$\n",
    "\\mathbf X = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1\\end{pmatrix}\\quad \\text{ y }\\quad \\mathbf \\beta = \\begin{pmatrix} \\mu \\\\ \\lambda \\end{pmatrix},\n",
    "$$\n",
    "y que, puesto que las variables son independientes\n",
    "$$\n",
    "\\mathbf \\Sigma = \\sigma^2 \\mathbb I_3,\n",
    "$$ \n",
    "obtenemos que \n",
    "$$\n",
    "\\mathbf Y \\sim \\mathcal N_3 (\\mathbf{X\\beta},\\sigma^2 \\mathbb I_3).\n",
    "$$\n",
    "\n",
    "Con esto sabemos por la teoría que si tenemos que \n",
    "\n",
    "$$ \n",
    "Y|X   \\equiv \\mbox{N}_n(X\\beta,\\sigma^2 \\mathbb{I}_n) \\Leftrightarrow Y = X\\beta + \\epsilon, \\ \\ \\epsilon|X\\equiv \\mbox{N}_n(0,\\sigma^2 \\mathbb{I}_n)\n",
    "$$\n",
    "\n",
    "Así que podemos decir que nuestro vector $\\mathbf Y$ verifica el modelo de regresión múltiple.\n",
    "\n",
    "**Apartado b)**.\n",
    "\n",
    "Ahora, para obtener el estimador de máxima verosimilitud **en general** (es decir: para cualquier modelo de regresión lineal), que en este caso es el de mínimos cuadrados) realizar el cálculo:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (\\mathbf X' \\mathbf X)^{-1}\\mathbf X'\\mathbf Y\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39597ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"MASS\")\n",
    "library(\"FRACTION\")\n",
    "X = cbind(c(1,0,1),c(0,1,1))\n",
    "\n",
    "mat = fra.m(ginv(t(X) %*% X)%*%t(X))\n",
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a94fcd",
   "metadata": {},
   "source": [
    "Por lo que, nuestro estimador de máxima verosimilitud es\n",
    "\n",
    "$$\n",
    "\\hat \\beta  = \\begin{pmatrix} \\hat \\mu \\\\ \\hat  \\lambda \\end{pmatrix} = \\frac{1}{3}\\begin{pmatrix} 2 & -1 & 1 \\\\ -1 & 2 & 1 \\end{pmatrix} \\begin{pmatrix} Y_1 \\\\ Y_2 \\\\ Y_3 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2 Y_1 - Y_2 + Y_3 \\\\ -Y_1 + 2 Y_2 + Y_3 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**Apartado c)**\n",
    "\n",
    "Por último, sabemos también que la distribución de $\\hat \\beta$ viene dada por \n",
    "\n",
    "$$\n",
    "\\hat{\\beta} \\equiv \\mathcal{N}_{p+1}(\\beta,\\sigma^2 (X'X)^{-1}),\n",
    "$$\n",
    "\n",
    "donde, en este caso $p = 1$, luego sería una normal bidimensional. Calculamos $(X'X)^{-1}$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fra.m(ginv(t(X) %*% X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea9a4a",
   "metadata": {},
   "source": [
    "Por lo que, la distribución del vector $\\hat \\beta = (\\hat \\mu, \\hat \\lambda)'$ es :\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} \\equiv \\mathcal{N}_{2}\\left(\\begin{pmatrix} \\mu \\\\ \\lambda \\end{pmatrix},\\frac{\\sigma^2}{3} \\begin{pmatrix}2 & -1 \\\\ -1 & 2 \\end{pmatrix}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87449e5a",
   "metadata": {},
   "source": [
    "# Ejercicio 10\n",
    "\n",
    "Los datos fuel2001 del fichero `combustible.RData` corresponden al consumo de combustible (y otras variables relacionadas) en los estados de EE.UU. Se desea explicar la variable `FuelC` en función del resto de la información.\n",
    "\n",
    "**Apartado a)** representa en un plano las dos primeras componentes principales de estos datos estandarizados (consulta la ayuda de `prcomp`) ¿ Son suficientes estas dos componentes para explicar un alto porcentaje de la varianza ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d1a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"combustible.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1799c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(fuel2001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a259ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y <- fuel2001$FuelC\n",
    "fuel2001$FuelC <- NULL\n",
    "\n",
    "# Standardize data\n",
    "standardized <- scale(fuel2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_comps <- prcomp(standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb62ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_fuel <- data.frame(\n",
    "  PC1 = principal_comps$x[, 1],\n",
    "  PC2 = principal_comps$x[, 2]\n",
    ")\n",
    "ggplot(pca_fuel, aes(x = PC1, y = PC2)) +\n",
    "  geom_point(col=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aea4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(principal_comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aff86c",
   "metadata": {},
   "source": [
    "Vemos que si sumamos la proporción de la varianza  (*Cumulative Proportion*) que explican las dos primeras componentes principales es $0.7190$. Este porcentaje aunque es razonablemente alto, está dejando sin explicar casi un $30\\%$ de la varianza, por lo que quizá  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8fe5f",
   "metadata": {},
   "source": [
    "**Apartado b)** Ajusta el modelo completo con todas las variables. En este modelo completo, contrasta la hipótesis nula de que los coeficientes de las variables `Income,MPC` y `Tax` son simultáneamente iguales a cero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7196352",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg <- lm(Y~., data=fuel2001)\n",
    "summary(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d544f09d",
   "metadata": {},
   "source": [
    "Obtenemos que nuestro coeficiente $R^2$ es de $\\approx0.98$, que es bastante cercano a $1$, por lo que podemos decir que estamos explicando la mayoría de la variabilidad de nuestros datos. \n",
    "\n",
    "Ajustamos ahora el modelo en el que hacemos que `Income, MPC` y `Tax` son iguales a cero. Esto es lo mismo que decir que el resto de variables son las que aportan al modelo, lo cual lo podemos indicar en la función `lm` de la forma:\n",
    "`lm(variable_a_predecir ~ v_dep_1 + ... + v_dep_n,...)` donde `v_dep_i` es la variable dependiente $i-$ésima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f90842",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg0 <- lm(Y~Drivers + Pop + Miles, data=fuel2001)\n",
    "summary(reg0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f29e9c",
   "metadata": {},
   "source": [
    "En este caso, tenemos un ligero descenso en el coeficiente $R^2$, aunque el descenso sea de apenas unas centésimas, por lo que este modelo está consiguiendo muy buenos resultados sin usar el mismo número de variables que usaba el anterior.\n",
    "\n",
    "Contrastamos la hipótesis nula $H_0$ haciendo la tabla *Anova*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60121c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova(reg0, reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d775b",
   "metadata": {},
   "source": [
    "Vemos que obtenemos un $p-$valor de $\\approx 0.16$, así que si consideramos (como es habitual) un $\\alpha = 0.05$, tendríamos que $p-$value $> \\alpha$ por lo que no tendríamos evidencia suficiente para rechazar $H_0$, es decir, que puede ser que estas variables indicadas no tengan una gran influencia en el modelo. Esto tiene sentido con el breve análisis anterior en el que comentábamos que el modelo con menos variables es prácticamente igual al modelo completo.\n",
    "\n",
    "**Apartado c)** De acuerdo con el método iterativo hacia adelante y el criterio BIC,  ¿ cuál es el modelo óptimo ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23088854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_models <- leaps::regsubsets(Y ~ ., data=fuel2001)\n",
    "summary_all <- summary(all_models)\n",
    "resumen_todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1856301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
